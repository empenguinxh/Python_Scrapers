{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# \u5f15\u5b50\n",
      "\n",
      "\u5ed6\u96ea\u5cf0\u8001\u5e08\u7684\u5728\u7ebf\u6559\u7a0b\u7cfb\u5217\u5f88\u4e0d\u9519\uff0c\u8fd9\u4e2anotebook\u5c1d\u8bd5\u7740\u5c06\u5176\u4e2d\u7684[python\u7cfb\u5217](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000)\u4e0b\u8f7d\u5230\u672c\u5730\u3002\n",
      "\n",
      "\u8be5\u811a\u672c\u5c06python\u6559\u7a0b\u7684\u6bcf\u4e2a\u7ae0\u8282\u5355\u72ec\u5b58\u4e3a\u672c\u5730\u7684html\u6587\u6863\uff0c\u4ee5`chapter0.html`\u3001`chapter1.html`\u7b49\u5f62\u5f0f\u547d\u540d\u3002\u540c\u65f6\uff0c\u56fe\u7247\u3001\u89c6\u9891\u672c\u5730\u5316\u3001\u4ee3\u7801\u9ad8\u4eae\u5316\u3002\n",
      "\n",
      "\u5f00\u59cb\u4e4b\u524d\u641c\u7d22\u4e86\u7f51\u4e0a\u73b0\u6210\u7684\u811a\u672c\uff0c\u9664\u4e86[\u6293\u53d6\u5ed6\u96ea\u5cf0\u7684Git\u6559\u7a0b](http://crossin.me/forum.php?mod=viewthread&tid=724)\u5916\uff0c\u5176\u4ed6\u7684\u601d\u8def\u90fd\u4e0d\u6e05\u6670\u3002\n",
      "\n",
      "\u672c\u6587\u7684\u57fa\u672c\u601d\u8def\u4eff\u7167\u90a3\u4e2a\u5e16\u5b50\uff0c\u5148\u4ece\u76ee\u5f55\u9875\u62bd\u53d6\u6240\u6709\u7ae0\u8282\u7684\u7f51\u5740\uff0c\u7136\u540e\u4f7f\u7528beautifulsoup\u6293\u53d6\u6709\u7528\u7684\u5185\u5bb9\uff0c\u5373`<div class=\"x-wiki-content\">...</div>`\u4e4b\u95f4\u7684\u5185\u5bb9\uff0c\u6700\u540e\u8f93\u51fa\u6210\u7f51\u9875\u3002\n",
      "\n",
      "\u53e6\u5916\uff0c\u672c\u6587\u8fd8\u6db5\u76d6\u4e86epub\u7684\u5236\u4f5c\u8fc7\u7a0b\u3002\n",
      "\n",
      "sync_to_file_magic_command.py\u91cc\u6709\u6211\u81ea\u5df1\u5199\u7684magic command\uff0c\u7528\u6765\u5c06\u6307\u5b9a\u683c\u5b50\u7684\u4ee3\u7801\u5199\u5165\u6307\u5b9a\u6587\u4ef6\uff0c\u65b9\u4fbf\u81ea\u52a8\u5316\u751f\u6210\u811a\u672c\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%run sync_to_file_magic_command.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "script_file = 'download_tutorial_python.py'\n",
      "convert_to_epub_file = 'convert_to_epub_python.py'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file $convert_to_epub_file -m o\n",
      "\n",
      "# coding: utf-8\n",
      "import os\n",
      "import requests\n",
      "import json\n",
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sync_to_file $script_file\n",
      "import codecs\n",
      "from pygments import highlight\n",
      "from pygments.lexers import get_lexer_by_name\n",
      "from pygments.formatters import HtmlFormatter\n",
      "from multiprocessing.dummy import Pool as ThreadPool"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $convert_to_epub_file\n",
      "import re\n",
      "from ebooklib import epub"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "\u5168\u5c40\u53d8\u91cf"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u4e0d\u540c\u7684\u6559\u7a0b\u53ea\u9700\u66f4\u6539`tutorial_name`\u53ca`home_page_url`\u4e24\u4e2a\u53d8\u91cf\u5373\u53ef\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file $convert_to_epub_file\n",
      "\n",
      "tutorial_name = 'python'\n",
      "home_page_url = '/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000'\n",
      "\n",
      "website_domain = 'http://www.liaoxuefeng.com'\n",
      "tutorial_name_prefix = tutorial_name + '_'\n",
      "temp_folder = tutorial_name_prefix + 'temp'\n",
      "parent_folder = tutorial_name_prefix + 'htmls'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sync_to_file $script_file\n",
      "lexer = get_lexer_by_name(tutorial_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# \u6293\u53d6\u76ee\u5f55\u9875\n",
      "\n",
      "\u5c06\u6240\u6709\u7684\u7ae0\u8282\u540d\u548c\u7ae0\u8282\u94fe\u63a5\u5b58\u653e\u5728\u53d8\u91cf`content_url_l`\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_content_url():\n",
      "    r = requests.get(website_domain + home_page_url)\n",
      "    home_soup = BeautifulSoup(r.content, 'lxml')\n",
      "    content_ul = home_soup.find('ul', {'class':'uk-nav uk-nav-side', 'style':'margin-right:-15px;'})\n",
      "    content_title_url_l = []\n",
      "    for tmp_index, tmp_content_a in enumerate(content_ul.find_all('a')):\n",
      "        content_title_url_l.append((tmp_content_a.text, tmp_content_a['href']))\n",
      "    return content_title_url_l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "content_title_url_l = get_content_url()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test whether the content url list is correctly gathered\n",
      "def unit_test(test_index):\n",
      "    content_title_url_l = get_content_url()\n",
      "    print content_title_url_l[test_index][0], '\\n', content_title_url_l[test_index][1]\n",
      "    print '%d chapters in total'%len(content_title_url_l)\n",
      "    test_content_url = website_domain + content_title_url_l[test_index][1]\n",
      "    print content_title_url_l[test_index][0], test_content_url\n",
      "    test_soup = BeautifulSoup(requests.get(test_content_url).content, 'lxml')\n",
      "    print test_soup\n",
      "#unit_test(4)\n",
      "del unit_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u672c\u8282\u5b9e\u9a8c\u4e86\u5982\u4f55\u5f97\u5230\u5b50\u7ae0\u8282\u7684\u76ee\u5f55\u3002\u4e0b\u9762\u63a2\u7d22\u5982\u4f55\u5904\u7406\u5355\u4e2a\u7ae0\u8282\u3002\n",
      "\n",
      "# \u5904\u7406\u5355\u4e2a\u7ae0\u8282\n",
      "\n",
      "\u8fd9\u4e00\u90e8\u5206\uff0c\u901a\u8fc7\u4e00\u6b65\u6b65\u5b9e\u9a8c\uff0c\u5199\u51fa\u7684\u6700\u7ec8\u51fd\u6570\u5177\u6709\u5982\u4e0b\u529f\u80fd\u3002\u8bfb\u5165\u4e00\u4e2a\u7f51\u5740\uff0c\u5c06\u7f51\u9875\u7684\u6b63\u6587\u90e8\u5206\u63d0\u53d6\u51fa\u6765\u3002\u5904\u7406\u8fc7\u7a0b\u4e2d\uff0ccss\u3001\u56fe\u7247\u4ee5\u53ca\u89c6\u9891\u90fd\u4f1a\u672c\u5730\u5316\u3002\n",
      "\n",
      "\u4f7f\u7528[\u4f7f\u7528list\u548ctuple](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014316724772904521142196b74a3f8abf93d8e97c6ee6000)\u4e00\u8282\uff08\u7b2c11\u8282\uff09\u4f5c\u4e3a\u63a2\u7d22\u3002\u56e0\u4e3a\u8fd9\u8282\u65e2\u6709\u56fe\u7247\u53c8\u6709\u4ee3\u7801\u3002\n",
      "\n",
      "\u6b63\u6587\u7684\u5185\u5bb9\u5f88\u597d\u63d0\u53d6\uff0c\u5728`<div class='x-wiki-content'>`...`</div>`\u4e4b\u95f4\u3002\n",
      "\n",
      "\u56fe\u7247\u7a0d\u5fae\u9ebb\u70e6\u4e00\u4e9b\u3002\u539f\u672c\u7684\u56fe\u7247\u662f\u6ca1\u6709\u6269\u5c55\u540d\u7684\uff0c\u4f46\u5176\u5b57\u8282\u7801\u4e2d\uff08\u5934\u90e8\uff09\u5e94\u8be5\u6307\u793a\u4e86\u6587\u4ef6\u89e3\u7801\u8be5\u7528\u7684\u683c\u5f0f\uff08PNG\uff09\u3002python\u5185\uff0c\u91c7\u7528'wb'\u6a21\u5f0f\uff0c\u76f4\u63a5\u628a\u5f97\u5230\u7684\u5b57\u8282\u7801\u5199\u4e3a\u6587\u4ef6\u3002\u89c6\u9891\u4e5f\u662f\u505a\u7c7b\u4f3c\u5904\u7406\u3002\n",
      "\n",
      "css\u90e8\u5206\uff0c\u7531\u4e8e\u6211\u4eec\u53ea\u5173\u6ce8\u6b63\u6587\u7684\u5185\u5bb9\uff0c\u9664\u4e86\u4ee3\u7801\u9ad8\u4eae\u5916\uff0c\u5176\u4ed6\u7684\u683c\u5f0f\u90fd\u4e0d\u9700\u8981\u3002\u800c\u4ee3\u7801\u90e8\u5206\uff0c\u7528request\u5f97\u5230\u7684\u7f51\u9875\u53ea\u6709`<code>...</code>`\u4e4b\u95f4\u7684\u539f\u59cb\u5185\u5bb9\uff0c\u672a\u7ecf\u6e32\u67d3\uff0c\u6ca1\u6709\u8bed\u6cd5\u9ad8\u4eae\u3002\u8fd9\u91cc\u624b\u52a8\u4f7f\u7528pygments\u6765\u52a0\u9ad8\u4eae\u5e76\u66ff\u6362\u539f\u6587\u5185\u5bb9\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "test_url = website_domain + content_title_url_l[11][1]\n",
      "test_html_str = requests.get(test_url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u5904\u7406\u56fe\u7247\n",
      "\n",
      "\u5148\u83b7\u53d6\u56fe\u7247\u7684\u5730\u5740"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_wiki_content = BeautifulSoup(test_html_str.content, 'lxml').find('div', {'class': 'x-wiki-content'})\n",
      "test_img_url = test_wiki_content.img['src']\n",
      "print test_wiki_content.img\n",
      "print test_img_url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u4e0b\u9762\u7684test\u5c06\u4e8c\u8fdb\u5236\u6570\u636e\u5199\u5165\u6587\u4ef6\uff0c\u540c\u65f6\u4fee\u6539html\u6e90\u7801\u4e2dimg\u7684\u94fe\u63a5\u5730\u5740\u5e76\u5c06\u4fee\u6539\u7684\u7ed3\u679c\u5b58\u4e3a\u6587\u4ef6`test_html.html`\uff0c\u4ee5\u9a8c\u8bc1\u56fe\u7247\u80fd\u5426\u6b63\u5e38\u663e\u793a\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# test\n",
      "def unit_test():\n",
      "    test_img_url = test_wiki_content.img['src']\n",
      "    test_image_bc = requests.get(website_domain+test_img_url).content\n",
      "    test_dir = os.path.dirname(test_img_url[1:])\n",
      "    if not os.path.exists(test_dir):\n",
      "        os.makedirs(test_dir)\n",
      "    with open(test_img_url[1:], 'wb') as f:\n",
      "        f.write(test_image_bc)\n",
      "    test_wiki_content.img['src'] = test_img_url[1:]\n",
      "    with codecs.open('test_html.html', 'w', encoding='utf-8') as f:\n",
      "        f.write(test_wiki_content.prettify())\n",
      "#unit_test()\n",
      "del unit_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u9ad8\u4eae\u4ee3\u7801\n",
      "\n",
      "\u5c06pygments\u63d0\u4f9b\u7684css\u6e90\u7801\u4fdd\u5b58\u4e3a\u6587\u4ef6"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "with codecs.open('styles.css', 'w', encoding='utf-8') as f:\n",
      "    f.write(HtmlFormatter().get_style_defs('.highlight'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u5f97\u5230html\u6e90\u7801\u5e76\u8f6c\u6362\u4e3asoup\u5bf9\u8c61\u540e\uff0c\u9996\u5148\u4ececode\u6807\u7b7e\u4e2d\u63d0\u53d6\u5185\u5bb9\uff0c\u7528pygments\u9ad8\u4eae\u3002\u4f46\u7ecfpygments\u8f6c\u6362\uff0c\u5f97\u5230\u7684\u662f\u5b57\u7b26\u4e32\uff0c\u9700\u8981\u5148\u8f6c\u6362\u4e3a\u4e34\u65f6soup\uff0c\u518d\u7528\u8fd9\u4e2a\u4e34\u65f6soup\u66ff\u6362\u539fsoup\u4e2d\u7684\u76f8\u5e94\u90e8\u5206\u3002\n",
      "\n",
      "\u66ff\u6362\u65f6\uff0c\u4f7f\u7528soup\u7684replace_with\u65b9\u6cd5\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "test_wiki_content = BeautifulSoup(test_html_str.content, 'lxml').find('div', {'class': 'x-wiki-content'})\n",
      "test_code_block = test_wiki_content.find('code')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Raw code:'\n",
      "print test_code_block.get_text()\n",
      "test_highlight = highlight(test_code_block.get_text(), lexer, HtmlFormatter())\n",
      "print 'Highlighted code:'\n",
      "print test_highlight\n",
      "test_highlight_soup = BeautifulSoup(test_highlight, 'lxml').div\n",
      "print 'Convert', type(test_highlight), 'to', type(test_highlight_soup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# test\n",
      "def unit_test():\n",
      "    _ = test_code_block.replace_with(test_highlight_soup)\n",
      "    with codecs.open('test_html.html', 'w', encoding='utf-8') as f:\n",
      "        header = '<!DOCTYPE html>\\n<head>\\n<link rel=\"stylesheet\" href=\"styles.css\">\\n</head>\\n<body>'\n",
      "        f.write(header)\n",
      "        f.write(test_wiki_content.prettify())\n",
      "        f.write('</body>')\n",
      "#unit_test()\n",
      "del unit_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u4e0b\u8f7d\u89c6\u9891\n",
      "\n",
      "\u4ee5\u7ae0\u8282[\u5b9a\u4e49\u51fd\u6570](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431679203477b5b364aeba8c4e05a9bd4ec1b32911e2000)\u4e3a\u4f8b\uff08\u7b2c17\u8282\uff09\n",
      "\n",
      "\u539f\u7f51\u9875\u4e2d\uff0c\u6bcf\u4e2a\u89c6\u9891\u90fd\u6709\u4e24\u4e2a`<source>`tag\uff0c\u4e00\u4e2a\u6307\u5411\u56fd\u5185\u7684github\uff0c\u53e6\u4e00\u4e2a\u6307\u5411github\u3002\u4f30\u8ba1\u540e\u8005\u662f\u5907\u7528\u5730\u5740\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528github\u7684\u5730\u5740\uff0c\u5e76\u4e14\u5220\u9664\u6389\u6e90\u7801\u4e2d\u591a\u4f59\u7684tag\uff0c\u7136\u540e\u5c06src\u6307\u5411\u672c\u5730\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unit_test():\n",
      "    test_url = website_domain + content_url_l[17][1]\n",
      "    test_html_str = requests.get(test_url).content\n",
      "    test_soup = BeautifulSoup(test_html_str, 'lxml')\n",
      "    test_wiki_content = test_soup.find('div', {'class': 'x-wiki-content'})\n",
      "    for video_index, video_tag in enumerate(test_wiki_content.find_all('video')):\n",
      "        source_tag = video_tag.source\n",
      "        github_url = source_tag.source['src']\n",
      "        source_tag.clear()\n",
      "        video_bc = requests.get(github_url).content\n",
      "        video_save_file_name = 'test_video_{}.mp4'.format(video_index)\n",
      "        with open(video_save_file_name, 'wb') as f:\n",
      "            f.write(video_bc)\n",
      "        source_tag['src'] = video_save_file_name\n",
      "        print source_tag\n",
      "    with codecs.open('test_html.html', 'w', encoding='utf-8') as f:\n",
      "        f.write(test_wiki_content.prettify())\n",
      "#unit_test()\n",
      "del unit_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u6574\u5408\n",
      "\n",
      "\u4e00\u822c\u56fe\u7247\u90fd\u662f\u653e\u5728\u67d0\u4e2a\u6587\u4ef6\u5939\u4e0b\uff0c\u4ee5\u201c0\u201d\u547d\u540d\u3002\n",
      "\n",
      "\u4f46\u6709\u7684\u7f51\u9875\uff0c\u6bd4\u5982[Day 9 - \u7f16\u5199API](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014323391480651a75b5fda4cb4c789208191682fc2c70000)\uff0c\u56fe\u7247\u5730\u5740\u4e3a`/files/attachments/001402403872210f486e3db3d4f4314acbfc0cc97006b32000/`\uff0c\u6ca1\u6709\u5177\u4f53\u7684\u6587\u4ef6\u540d\u3002\n",
      "\n",
      "\u6240\u4ee5\uff0c\u5c06\u56fe\u7247\u5730\u5740\u6309\u7167'/'\u62c6\u5206\uff0c\u53d6\u5012\u6570\u7b2c\u4e8c\u4e2a\u5b50\u4e32\u3002\n",
      "\n",
      "\u53e6\u5916\uff0c\u6240\u6709\u56fe\u7247\u7684\u4e0a\u7ea7\u6587\u4ef6\u5939\u90fd\u6309\u7167\u6240\u5c5e\u7ae0\u8282\u7684\u5e8f\u53f7\u7edf\u4e00\u547d\u540d\u3002\n",
      "\n",
      "\u6700\u540e\uff0c\u7531\u4e8e\u4f7f\u7528\u591a\u8fdb\u7a0b\uff0c\u5f88\u53ef\u80fd\u51fa\u73b0\u4e24\u4e2a\u4ee5\u4e0a\u7684\u8fdb\u7a0b\u540c\u65f6\u8981\u521b\u5efa\u540c\u4e00\u4e2a\u6587\u4ef6\u5939\u7684\u60c5\u5f62\u3002\u6240\u4ee5\u91c7\u7528try\u7684\u5f62\u5f0f\uff0c\u5ffd\u7565\u65e0\u6743\u9650\u7684\u95ee\u9898\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file\n",
      "def process_one_img(par_tuple):\n",
      "    img_tag, chap_index = par_tuple\n",
      "    img_src = img_tag['src']\n",
      "    if not img_src.startswith('/files'):\n",
      "        img_tag['src'] = ''\n",
      "        return\n",
      "    sub_str_l = img_src.split('/')\n",
      "    img_rel_path = 'chapter_' + unicode(chap_index) + '/' + sub_str_l[-2]\n",
      "    if not (sub_str_l[-1] is None):\n",
      "        img_rel_path += '_' + sub_str_l[-1]\n",
      "    img_full_path = parent_folder + '/' + img_rel_path\n",
      "    if not os.path.isfile(img_full_path):\n",
      "        img_dir = os.path.dirname(img_full_path)\n",
      "        try:\n",
      "            if not os.path.exists(img_dir):\n",
      "                os.makedirs(img_dir)\n",
      "        except WindowsError:\n",
      "            pass\n",
      "        img_bc = requests.get(website_domain + img_src).content\n",
      "        with open(img_full_path, 'wb') as f:\n",
      "            f.write(img_bc)\n",
      "    img_tag['src'] = img_rel_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file\n",
      "def process_one_chapter(chap_soup, pool, chap_index):\n",
      "    chap_wiki_content = chap_soup.find('div', {'class': 'x-wiki-content'})\n",
      "    if chap_wiki_content is None:\n",
      "        print chap_soup.prettify()\n",
      "    # save img and use multithread\n",
      "    par_l = [(img_tag, chap_index) for img_tag in chap_wiki_content.find_all('img')]\n",
      "    _ = pool.map(process_one_img, par_l)\n",
      "    # highlight code\n",
      "    for code_tag in chap_wiki_content.find_all('code'):\n",
      "        if code_tag.parent.name != 'pre':\n",
      "            # skip inline code\n",
      "            continue\n",
      "        highlight_str = highlight(code_tag.get_text(), lexer, HtmlFormatter())\n",
      "        highlight_div = BeautifulSoup(highlight_str, 'lxml').div\n",
      "        _ = code_tag.replace_with(highlight_div)\n",
      "    # save video\n",
      "    process_video(chap_wiki_content, chap_index)\n",
      "    # generate html\n",
      "    header = '<!DOCTYPE html>\\n<head>\\n<meta charset=\"utf-8\"/>\\n<link rel=\"stylesheet\" href=\"styles.css\">\\n'\n",
      "    header += '<title>' + chap_soup.title.get_text().strip() + '</title>\\n</head>\\n<body>'\n",
      "    header += '\\n<h4>' + chap_soup.h4.get_text().strip() + '</h4>\\n'\n",
      "    html_str = header + chap_wiki_content.prettify() + '</body>'\n",
      "    return html_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file\n",
      "def process_video(chap_wiki_soup, chap_index):\n",
      "    for video_index, video_tag in enumerate(chap_wiki_soup.find_all('video')):\n",
      "        source_tag = video_tag.source\n",
      "        github_url = source_tag.source['src']\n",
      "        video_rel_path = 'chapter_{}/chapter_{}_video_{}.mp4'.format(chap_index, chap_index, video_index)\n",
      "        video_full_path = parent_folder + '/' + video_rel_path\n",
      "        video_dir = os.path.dirname(video_full_path)\n",
      "        source_tag['src'] = video_rel_path\n",
      "        source_tag.clear()\n",
      "        if os.path.isfile(video_full_path):\n",
      "            continue\n",
      "        video_bc = requests.get(github_url).content\n",
      "        if not os.path.exists(video_dir):\n",
      "            os.makedirs(video_dir)\n",
      "        with open(video_full_path, 'wb') as f:\n",
      "            f.write(video_bc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u8bbf\u95ee\u7f51\u5740\u5e76\u53d6\u56de\u5185\u5bb9\u8fd9\u4e00\u6b65\uff0c\u7531\u4e8e\u6211\u4e0d\u4f1a\u534f\u7a0b\uff0c\u6240\u4ee5\u91c7\u7528\u5f88\u7b28\u7684\u65b9\u6cd5\uff0c\u5faa\u73af\u91cd\u8bd5...\n",
      "\n",
      "\u4e3a\u4e86\u907f\u514d\u5931\u8d25\u540e\u4ece\u5934\u518d\u6765\uff0c\u5c06\u5df2\u7ecf\u6210\u529f\u8bfb\u53d6\u7684\u7f51\u9875\u5185\u5bb9\u5b58\u5230\u672c\u5730\u3002\n",
      "\n",
      "+ `+`\u8868\u793a\u6210\u529f\u53d6\u5f97\u6b63\u6587\u5185\u5bb9\u3002\n",
      "+ `-503-`\u8868\u793a\u8fd4\u56de\u7684\u662f`503 Service Temporarily Unavailable`\n",
      "+ `-ce-`\u8868\u793aConnectionError\uff08\u4e00\u822c\u662f\u8d85\u8fc7\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff09\n",
      "+ `-t-`\u8868\u793a\u8fde\u63a5\u8d85\u65f6\u3002\n",
      "+ `-cache-`\u8868\u793a\u4f7f\u7528\u4e4b\u524d\u5b58\u50a8\u8fc7\u7684\u7248\u672c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sync_to_file $script_file\n",
      "def get_chap_soup(chap_url, use_cache=True):\n",
      "    chap_temp_file_name = chap_url.replace('/', '_')\n",
      "    chap_temp_file_full_path = temp_folder + '/' + chap_temp_file_name\n",
      "    \n",
      "    if use_cache and os.path.isfile(chap_temp_file_full_path):\n",
      "        print '-cache-',\n",
      "        with codecs.open(chap_temp_file_full_path, 'r', encoding='utf-8') as f:\n",
      "            chap_soup = BeautifulSoup(f.read(), 'lxml')\n",
      "        return chap_soup\n",
      "    \n",
      "    while True:\n",
      "        try:\n",
      "            r = requests.get(website_domain + chap_url, timeout=10)\n",
      "        except requests.ConnectionError:\n",
      "            print '-ce-',\n",
      "        except requests.Timeout:\n",
      "            print '-t-',\n",
      "        else:\n",
      "            if r.status_code == 503:\n",
      "                print '-503-',\n",
      "            else:\n",
      "                print '+',\n",
      "                chap_soup = BeautifulSoup(r.content, 'lxml')\n",
      "                break\n",
      "        \n",
      "    if use_cache:\n",
      "        if not os.path.exists(temp_folder):\n",
      "            os.makedirs(temp_folder)\n",
      "        with codecs.open(chap_temp_file_full_path, 'w', encoding='utf-8') as f:\n",
      "            f.write(r.content.decode('utf-8'))\n",
      "    \n",
      "    return chap_soup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unit_test(test_index):\n",
      "    print 'Processing chapter', content_title_url_l[test_index][0]\n",
      "    chap_url = content_title_url_l[test_index][1]\n",
      "    chap_soup = get_chap_soup(chap_url)\n",
      "    pool = ThreadPool(4)\n",
      "    test_html = process_one_chapter(chap_soup, pool, test_index)\n",
      "    with codecs.open(parent_folder + '/test_html.html','w',encoding='utf-8') as f:\n",
      "        f.write(test_html)\n",
      "#unit_test(17)\n",
      "del unit_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# \u4e0b\u8f7d\u6574\u4e2a\u6559\u7a0b\n",
      "\n",
      "\u56e0\u4e3aipython\u4e0d\u652f\u6301python\u539f\u751f\u7684\u591a\u8fdb\u7a0b\u3001\u591a\u7ebf\u7a0b\u6a21\u5757\uff0c\u6240\u4ee5\u5c06\u4ee3\u7801\u5199\u5165\u811a\u672c\uff0c\u7136\u540e\u76f4\u63a5\u8fd0\u884c\u3002\n",
      "\n",
      "\u56e0\u4e3a\u5e76\u53d1\u5904\u7406\u7684\u4e0d\u597d\uff0c\u6240\u4ee5\u5f88\u53ef\u80fd\u5728\u4e0b\u8f7d\u7f51\u9875\u6216\u56fe\u7247\u65f6\u5361\u4f4f\u3002\u591a\u8fd0\u884c\u51e0\u6b21\u5c31\u597d\u4e86\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file\n",
      "def get_soup_l():\n",
      "    home_soup = BeautifulSoup(requests.get(website_domain + home_page_url).content, 'lxml')\n",
      "    content_ul = home_soup.find('ul', {'class':'uk-nav uk-nav-side', 'style':'margin-right:-15px;'})\n",
      "    content_title_l = []\n",
      "    content_url_l = []\n",
      "    for _index, content_a in enumerate(content_ul.find_all('a')):\n",
      "        content_url_l.append(content_a['href'])\n",
      "        content_title_l.append(content_a.text)\n",
      "    pool = ThreadPool(4)\n",
      "    chap_soup_l = pool.map(get_chap_soup, content_url_l)\n",
      "    return chap_soup_l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file\n",
      "def get_html_l(chap_soup_l):\n",
      "    html_l = []\n",
      "    if not os.path.isdir(parent_folder):\n",
      "        os.makedirs(parent_folder)\n",
      "    for chap_index, chap_soup in enumerate(chap_soup_l):\n",
      "        pool = ThreadPool(6)\n",
      "        one_html = process_one_chapter(chap_soup, pool, chap_index)\n",
      "        html_l.append(one_html)\n",
      "        # write to file\n",
      "        file_name = parent_folder + '/chapter_' + unicode(chap_index) + '.html'\n",
      "        with codecs.open(file_name, 'w', encoding='utf-8') as f:\n",
      "            f.write(one_html)\n",
      "        print chap_index,\n",
      "    return html_l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $script_file -p\n",
      "if __name__ == '__main__':\n",
      "    if not os.path.exists(parent_folder):\n",
      "        os.makedirs(parent_folder)\n",
      "    print '\\n Get htmls'\n",
      "    soup_l_file = tutorial_name_prefix + 'soup_l_file.txt'\n",
      "    html_l_file = tutorial_name_prefix + 'html_l_file.txt'\n",
      "    if not os.path.isfile(soup_l_file):\n",
      "        _soup_l = get_soup_l()\n",
      "        _soup_l_str_l = [_soup.prettify() for _soup in _soup_l]\n",
      "        with open(soup_l_file, 'w') as f:\n",
      "            json.dump(_soup_l_str_l, f, indent=4)\n",
      "    else:\n",
      "        with open(soup_l_file, 'r') as f:\n",
      "            _soup_l = [BeautifulSoup(html_str, 'lxml') for html_str in json.load(f, encoding='utf-8')]\n",
      "    with codecs.open(parent_folder + '/styles.css', 'w', encoding='utf-8') as f:\n",
      "        f.write(HtmlFormatter().get_style_defs('.highlight'))\n",
      "    print '\\n Convert to html'\n",
      "    _html_l = get_html_l(_soup_l)\n",
      "    with open(html_l_file, 'w') as f:\n",
      "        json.dump(_html_l, f, indent=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# \u8f6c\u6362\u4e3aepub\n",
      "\n",
      "\u5230\u8fd9\u4e00\u6b65\uff0c\u5f53\u524d\u76ee\u5f55\u4e0b\u5e94\u8be5\u6709\u4e00\u4e2a`**htmls`\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709`chapter_0.html`\u81f3`chapter_122.html`\u4ee5\u53ca\u76f8\u5e94\u7684\u5a92\u4f53\u6587\u4ef6\u5939\u3002\n",
      "\n",
      "\u53e6\u5916\uff0c\u8fd8\u6709\u4e24\u4e2a\u6587\u4ef6\u3002\u4e00\u4e2a\u662f`**soup_l_file.txt`\uff0c\u5b58\u653e\u7684\u662f\u672a\u5904\u7406\u7684html\u6e90\u7801\uff0c\u53e6\u4e00\u4e2a\u662f`**html_l_file.txt`\uff0c\u5305\u542b\u5904\u7406\u8fc7\u7684html\u6e90\u7801\u3002\n",
      "\n",
      "\n",
      "\u8fd9\u4e00\u6b65\u4f7f\u7528\u6a21\u5757[ebooklib](https://github.com/aerkalov/ebooklib)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \u66f4\u8be6\u7ec6\u7684\u76ee\u5f55\n",
      "\n",
      "\u65e2\u7136\u8981\u505a\u6210epub\uff0c\u90a3\u4e48\u539f\u5148\u6241\u5e73\u5f0f\u7684\u76ee\u5f55\u5c31\u4e0d\u591f\u7528\u4e86\u3002\u539f\u6559\u7a0b\u4e2d\uff0c\u901a\u8fc7\u7f29\u8fdb\u7684\u65b9\u5f0f\uff0c\u533a\u5206\u4e86\u76ee\u5f55\u7684\u5c42\u7ea7\u3002\n",
      "\n",
      "\u539f\u6559\u7a0b\u6700\u591a\u6709\u4e09\u7ea7\u76ee\u5f55\uff0c\u6bd4\u5982\u201c\u51fd\u6570\u5f0f\u7f16\u7a0b\u201d->\u201c\u9ad8\u7ea7\u51fd\u6570\u201d->\u201cmap/reduce\u201d\u3002\u8fd9\u91cc\u4e3a\u4e86\u4fbf\u4e8e\u6d4f\u89c8\uff0c\u53ea\u4fdd\u7559\u524d\u4e24\u7ea7\u76ee\u5f55\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $convert_to_epub_file\n",
      "def get_detailed_content():\n",
      "    home_html_str = requests.get(website_domain + home_page_url).content\n",
      "    home_soup = BeautifulSoup(home_html_str, 'lxml')\n",
      "    content_ul = home_soup.find('ul', {'class':'uk-nav uk-nav-side', 'style':'margin-right:-15px;'})\n",
      "    is_first_level_l = []\n",
      "    for li_tag in content_ul.find_all('li'):\n",
      "        if li_tag.has_attr('style'):\n",
      "            indent_style = li_tag['style']\n",
      "            if indent_style.endswith('1em;'):\n",
      "                is_first_level_l.append(True)\n",
      "            else:\n",
      "                is_first_level_l.append(False)\n",
      "        else:\n",
      "            is_first_level_l.append(True)\n",
      "    return is_first_level_l\n",
      "\n",
      "first_level_indicator_l = get_detailed_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "\u5236\u4f5cepub"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%%sync_to_file $convert_to_epub_file\n",
      "html_l_file_name = tutorial_name_prefix + 'html_l_file.txt'\n",
      "\n",
      "with open(html_l_file_name, 'r') as f:\n",
      "    html_str_l = json.load(f, encoding='utf-8')\n",
      "    \n",
      "title = tutorial_name.capitalize() + u'\u6559\u7a0b'\n",
      "author = u'\u5ed6\u96ea\u5cf0'\n",
      "epub_name = '{}_tutorial.epub'.format(tutorial_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sync_to_file $convert_to_epub_file\n",
      "\n",
      "book = epub.EpubBook()\n",
      "# set metadata\n",
      "#book.set_identifier('id123456')\n",
      "book.set_language('cn')\n",
      "book.set_title(title)\n",
      "book.add_author(author)\n",
      "get_title = lambda _str: re.compile('<h4>(.*)</h4>').search(_str).group(1)\n",
      "\n",
      "toc_list = []\n",
      "spine_list = ['cov', 'nav']\n",
      "\n",
      "# add css\n",
      "hight_css = epub.EpubItem(uid=\"style_nav\", file_name=\"style.css\", media_type=\"text/css\")\n",
      "hight_css.content = open(parent_folder + '/styles.css', 'r').read()\n",
      "book.add_item(hight_css)\n",
      "\n",
      "section_list = None\n",
      "for chap_index, html_str in enumerate(html_str_l):\n",
      "    chap_title = get_title(html_str)\n",
      "    chap_uid = 'chapter_{:d}'.format(chap_index)\n",
      "    chap_file_name = chap_uid + '.xhtml'\n",
      "    # create chapter\n",
      "    one_chap = epub.EpubHtml(title=chap_title, file_name=chap_file_name, lang='cn', content=html_str)\n",
      "    one_chap.add_item(hight_css)\n",
      "    # add chapter\n",
      "    book.add_item(one_chap)\n",
      "    # toc\n",
      "    if first_level_indicator_l[chap_index]:\n",
      "        if not (section_list is None):\n",
      "            toc_list.append(section_list)\n",
      "        section_list = []\n",
      "        section_list.append(epub.Section(chap_title))\n",
      "        section_list.append([])\n",
      "        section_list[1].append(one_chap)\n",
      "    else:\n",
      "        section_list[1].append(one_chap)\n",
      "    #toc_list.append(epub.Link(chap_file_name, chap_title, chap_uid))\n",
      "    # spine\n",
      "    spine_list.append(one_chap)\n",
      "    # add picture and video\n",
      "    chap_pic_dir = parent_folder + '/' + chap_uid\n",
      "    if os.path.exists(chap_pic_dir):\n",
      "        for media_file_name in os.listdir(chap_pic_dir):\n",
      "            media_file_full_path = chap_pic_dir + '/' + media_file_name\n",
      "            media_file_save_path = chap_uid + '/' + media_file_name\n",
      "            media_data = open(media_file_full_path, 'rb').read()\n",
      "            if media_file_name.endswith('mp4'):\n",
      "                # video\n",
      "                media_type = 'video/mp4'\n",
      "            else:\n",
      "                # pic\n",
      "                media_type = 'image/png'\n",
      "            one_media = epub.EpubItem(uid=media_file_name,  file_name=media_file_save_path, \n",
      "                                      media_type=media_type, content=media_data)\n",
      "            book.add_item(one_media)\n",
      "toc_list.append(section_list)\n",
      "\n",
      "# define Table Of Contents\n",
      "book.toc = toc_list\n",
      "\n",
      "# add default NCX and Nav file\n",
      "book.add_item(epub.EpubNcx())\n",
      "book.add_item(epub.EpubNav())\n",
      "\n",
      "# define css style\n",
      "style = '''\n",
      "@namespace epub \"http://www.idpf.org/2007/ops\";\n",
      "body {\n",
      "    font-family: Cambria, Liberation Serif, Bitstream Vera Serif, Georgia, Times, Times New Roman, serif;\n",
      "}\n",
      "h2 {\n",
      "     text-align: left;\n",
      "     text-transform: uppercase;\n",
      "     font-weight: 200;     \n",
      "}\n",
      "ol {\n",
      "        list-style-type: none;\n",
      "}\n",
      "ol > li:first-child {\n",
      "        margin-top: 0.3em;\n",
      "}\n",
      "nav[epub|type~='toc'] > ol > li > ol  {\n",
      "    list-style-type:square;\n",
      "}\n",
      "nav[epub|type~='toc'] > ol > li > ol > li {\n",
      "        margin-top: 0.3em;\n",
      "}\n",
      "'''\n",
      "\n",
      "# add css file\n",
      "nav_css = epub.EpubItem(uid=\"style_nav\", file_name=\"style/nav.css\", media_type=\"text/css\", content=style)\n",
      "book.add_item(nav_css)\n",
      "\n",
      "\n",
      "# basic spine\n",
      "#book.set_cover(\"image.png\", pic_data)\n",
      "book.spine = spine_list\n",
      "# write to the file\n",
      "epub.write_epub(epub_name, book, {})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! jupyter nbconvert --to markdown download_blog.ipynb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}